e
library(rgl)
library(pheatmap)
# Load data
# data <- fread("~/practical/imaging/PrImR6_MEDs_SuperVoxels_npix3.txt", sep=",")
data <- read.table("~/practical/imaging/PrImR6_MEDs_SuperVoxels_npix3.txt", sep=",", header=T)
# Create matrices
loc <- data[,c(1,2,3)]
expr <- data[,-c(1,2,3)]
# Normalise
norm <- expr/max(expr)
# Informative plots
load("~/practical/imaging/surfacePoints3D_6pdf")
sert <- norm[,"sert"]
loc_sert <- loc[sert>0,]
asd <- cbind(loc_sert,cutree(tree, k=6))
d <- dist(loc_sert)
# m <- as.matrix(d)
tree <- hclust(d)
asd <- cbind(loc_sert,cutree(tree, k=4))
asd <- cbind(loc_sert,cutree(tree, k=6))
last_group <- rownames(asd[asd$Cluster==6,])
tmp <- cbind(loc_sert,cutree(tree, k=4))
colnames(tmp) <- c("Y","X","Z","Cluster")
tmp[rownames(tmp) %in% last_group,"Cluster"] <- 5
norm_sercells <- norm[sert>0,]
norm_sercells_filt <- norm[,colMeans(norm_sercells)>0]
colnames(norm_sercells_filt)
norm_sercells_filt$cluster <- tmp$Cluster
dim(tmp)
dim(norm)
dim(norm_sercells)
norm_sercells_filt <- norm_sercells[,colMeans(norm_sercells)>0]
norm_sercells_filt$cluster <- tmp$Cluster
dim(norm_sercells_filt)
View(norm_sercells_filt)
tmp <- norm_sercells_filt %>% group_by(cluster) %>% summarise_each(funs(mean))
library(tidyr)
library(dplyr)
tmp <- norm_sercells_filt %>% group_by(cluster) %>% summarise_each(funs(mean))
View(tmp)
table(tmp$cluster)
tmp[rownames(tmp) %in% last_group,"Cluster"] <- 5
table(tmp$cluster)
tree <- hclust(d)
tmp <- cbind(loc_sert,cutree(tree, k=4))
colnames(tmp) <- c("Y","X","Z","Cluster")
tmp[rownames(tmp) %in% last_group,"Cluster"] <- 5
norm_sercells_filt$cluster <- tmp$Cluster
foo <- norm_sercells_filt %>% group_by(cluster) %>% summarise_each(funs(mean))
View(foo)
tmp$Cluster
table(tmp$Cluster)
tree <- hclust(d)
tmp <- cbind(loc_sert,cutree(tree, k=4))
colnames(tmp) <- c("Y","X","Z","Cluster")
# asd <- cbind(loc_sert,cutree(tree, k=6))
# last_group <- rownames(asd[asd$Cluster==6,])
tmp[rownames(tmp) %in% last_group,"Cluster"] <- 5
table(tmp$Cluster)
last_group
asd <- cbind(loc_sert,cutree(tree, k=6))
last_group <- rownames(asd[asd$Cluster==6,])
last_group
asd
colnames(asd)
asd[,4]
last_group <- rownames(asd[asd[,4]==6,])
last_group
tmp[rownames(tmp) %in% last_group,"Cluster"] <- 5
table(tmp$Cluster)
# Take means within clusters
norm_sercells_filt$cluster <- tmp$Cluster
foo <- norm_sercells_filt %>% group_by(cluster) %>% summarise_each(funs(mean))
View(foo)
pheatmap(foo, border_color="black", main="Tom's plot",
cluster_cols=T, cluster_rows=T, show_rownames=F, show_colnames=T,
annotation_row=NA, annotation_col=NA, annotation_colors=NA,
legend=T, annotation_legend=FALSE, treeheight_row=20, treeheight_col=20,
fontsize_row=20, fontsize_col=15, cellheight=30)
pheatmap(foo[,-c("cluster")], border_color="black", main="Tom's plot",
cluster_cols=T, cluster_rows=T, show_rownames=F, show_colnames=T,
annotation_row=NA, annotation_col=NA, annotation_colors=NA,
legend=T, annotation_legend=FALSE, treeheight_row=20, treeheight_col=20,
fontsize_row=20, fontsize_col=15, cellheight=30)
foo[,-c("cluster")]
points3d(surf3d, aspect="iso", col="green", alpha=0.1)
points3d(tmp, aspect="iso", col=tmp[,"Cluster"], alpha=0.9)
View(foo)
foo[,"cluster"]
foo[,-c("cluster")]
foo[,"cluster"]
class(foo)
pheatmap(foo %>% select(-cluster), border_color="black", main="Tom's plot",
cluster_cols=T, cluster_rows=T, show_rownames=F, show_colnames=T,
annotation_row=NA, annotation_col=NA, annotation_colors=NA,
legend=T, annotation_legend=FALSE, treeheight_row=20, treeheight_col=20,
fontsize_row=20, fontsize_col=15, cellheight=30)
pheatmap(foo %>% select(-cluster), border_color="black", main="Tom's plot",
cluster_cols=T, cluster_rows=T, show_rownames=T, show_colnames=T,
annotation_row=NA, annotation_col=NA, annotation_colors=NA,
legend=T, annotation_legend=FALSE, treeheight_row=20, treeheight_col=20,
fontsize_row=20, fontsize_col=15, cellheight=30)
foo[,"Pikachu"]
foo
View(foo)
foo <- norm_sercells_filt %>% group_by(cluster) %>% summarise_each(funs(mean)) %>% select(-cluster)
hist(foo)
View(foo)
class(foo)
hist(as.matrix(foo))
foo <- norm_sercells_filt %>% group_by(cluster) %>% summarise_each(funs(mean)) %>% select(-cluster) %>% as.matrix
quantile(foo)
?quantile
View(foo)
apply(foo,2, function(x) sum(x>0.1))
which(apply(foo,2, function(x) sum(x>0.1)) == 1)
bar <- apply(foo,2, function(x) sum(x>0.1))
bar
bar[which(bar)==1]
bar[which(bar==1)]
pheatmap(foo %>% select(-cluster), border_color="black", main="Tom's plot",
cluster_cols=T, cluster_rows=T, show_rownames=T, show_colnames=T,
annotation_row=NA, annotation_col=NA, annotation_colors=NA,
legend=T, annotation_legend=FALSE, treeheight_row=20, treeheight_col=20,
fontsize_row=20, fontsize_col=15, cellheight=30)
pheatmap(foo, border_color="black", main="Tom's plot",
cluster_cols=T, cluster_rows=T, show_rownames=T, show_colnames=T,
annotation_row=NA, annotation_col=NA, annotation_colors=NA,
legend=T, annotation_legend=FALSE, treeheight_row=20, treeheight_col=20,
fontsize_row=20, fontsize_col=15, cellheight=30)
bar[which(bar==1)]
bar[which(bar==1)]
foo[,"Actub"]
View(foo)
bar <- apply(foo,2, function(x) x/sum(x) )
View(bar)
points3d(surf3d, aspect="iso", col="green", alpha=0.1)
points3d(tmp, aspect="iso", col=tmp[,"Cluster"], alpha=0.9)
View(foo)
max(foo)
points3d(surf3d, aspect="iso", col="green", alpha=0.1)
points3d(tmp, aspect="iso", col=tmp[,"Cluster"], alpha=0.9)
pheatmap(foo, border_color="black", main="Tom's plot",
cluster_cols=T, cluster_rows=T, show_rownames=T, show_colnames=T,
annotation_row=NA, annotation_col=NA, annotation_colors=NA,
legend=T, annotation_legend=FALSE, treeheight_row=20, treeheight_col=20,
fontsize_row=20, fontsize_col=15, cellheight=30)
rownames(foo) <- 1:5
pheatmap(foo, border_color="black", main="Tom's plot",
cluster_cols=T, cluster_rows=T, show_rownames=T, show_colnames=T,
annotation_row=NA, annotation_col=NA, annotation_colors=NA,
legend=T, annotation_legend=FALSE, treeheight_row=20, treeheight_col=20,
fontsize_row=20, fontsize_col=15, cellheight=30)
################################################
## Script to test PCA-like GFA vs FA-like GFA ##
################################################
scGFAfile <- "~/GFA/scGFA/R/scGFA.R"
# scGFAfile <- "/Users/ricard/GFA/CCAGFA_original/R/CCAGFA.R"
# scGFAfile <- "~/GFA/scGFA/gibbs_scGFA.R"
source("/Users/ricard/scMT/technical_test/compare_models/run_comparison/utils_simulate.R")
###################
## Generate data ##
###################
# Specify the options
N <- 100
D <- c(100,100,100)
K <- 6
M <- 3
Z <- matrix(0,N,K)
Z[,1] <- sin((1:N)/(N/20))
Z[,2] <- cos((1:N)/(N/20))
Z[,3] <- 2*((1:N)/N-0.5)
Z[,4] <- rnorm(N,0,1)
Z[,5] <- rnorm(N,0,1)
Z[,6] <- rnorm(N,0,1)
alpha <- matrix(0,M,K)
alpha[1,] <- c(1,1,1e6,1,1e6,1e6)
alpha[2,] <- c(1,1,1,1e6,1,1e6)
alpha[3,] <- c(1,1e6,1,1e6,1e6,1)
tau <- lapply(1:M, function(m) runif(D[m],min=0.1,max=3))
mu <- lapply(D, function(Dm) rep(0,Dm))
# Generate the data
data <- generate_data(N=N,D=D,K=K,M=M,tau=tau,mu=mu,alpha=alpha,Z=Z)
Y <- data$Y
Z <- data$Z
#############
## Run GFA ##
#############
# Initial number of latent variables
initial_K <- 10
source(scGFAfile)
opts <- getDefaultOpts()
opts$iter.max <- 300
opts$lb.freq <- 1
opts$verbose <- 2
opts$dropK <- T
opts$init.alpha = 100
K <- initial_K
trial=1
# Store dimensionalities of data sets
M <- length(Y)                    # The number of views
D <- unlist(lapply(Y,ncol))       # Collect the number of features in vector D
Ds <- sum(D)                      # Total number of features
N <- nrow(Y[[1]])                 # The number of samples
datavar <- lapply(Y,apply,2,var)  # The total variance of the data
effectiveK <- K
# Checks
if (K>N) stop("The number of latent variables have to be smaller than the number of samples")
if (any(K>D)) stop("The number of latent variables have to be smaller than the number of observed variables")
if (!is.na(opts$tmp.folder)) dir.create(opts$tmp.folder,recursive=T,showWarnings=F)
if (is.na(opts$save.freq)) opts$save.freq <- opts$iter.max+1
#if (is.na(opts$lb.freq)) opts$lb.freq = opts$iter.max
if (is.na(opts$covariates)) opts$covariates <- rep(K,FALSE)
if (is.na(opts$r.threshold)) opts$r.threshold <- 1.0
# hyperparameters
a0_alpha <- opts$prior.a_alpha    # a parameter of the p(alpha) gamma distribution
b0_alpha <- opts$prior.b_alpha    # b parameter of the p(alpha) gamma distribution
a0_tau <- opts$prior.a_tau        # a parameter of the p(tau) gamma distribution
b0_tau <- opts$prior.b_tau        # b parameter of the p(tau) gamma distribution
beta0_mu <- opts$prior.beta_mu     # beta parameter of the p(mu) normal distribution
##########################
## Initialize the model ##
##########################
# Performance control
lbound_terms <- matrix(nrow=opts$iter.max, ncol=6)    # For storing the lower bound terms
colnames(lbound_terms) <- c("lik","z","mu","w","alpha","tau")
lbound <- rep(NA,opts$iter.max)        # For storing the lower bounds
Ks <- rep(NA,opts$iter.max)                    # For storing the evolution of K
# Latent variables
if (class(opts$init.Z) == "matrix")
Z <- opts$init.Z
if (class(opts$init.Z) == "character") {
if (opts$init.Z == "random") {
Z <- matrix(rnorm(N*K,0,1),N,K)
} else if (opts$init.Z == "orthogonal") {
Z <- prcomp(matrix(rnorm(N*K,0,1),N,K))$x
} else if (opts$init.Z == "pca") {
Z <- scale(prcomp(Reduce(cbind,Y))$x[,1:K], center=T, scale=T)
} else {
stop("You have to specify an initialisation for Z")
}
}
covZ <- diag(1,K)               # The covariance
ZZ <- crossprod(Z,Z) + covZ*N             # The second moments
# means
mu <- vector("list",length=M)       # mean of q(mu)
sigmamu <- vector("list",length=M)  # variance of q(mu)
mumu <- vector("list",length=M)     # The second moments of q(mu)
for (m in 1:M) {
if (opts$init.mu == "maximum-likelihood") {
mu[[m]] <- apply(Y[[m]],2,mean)
} else {
mu[[m]] <- rep(opts$init.mu,D[m])
}
sigmamu[[m]] <- rep(1,D[m])
mumu[[m]] <- mu[[m]]**2 + sigmamu[[m]]
}
# noise
tau <- list()                   # The mean noise precisions
b_tau <- list()                 # b parameter of the q(tau) gamma distribution
a_tau <- a0_tau + N/2           # a parameter of the q(tau) gamma distribution
for (m in 1:M) {
tau[[m]] <- rep(opts$init.tau,D[m])
b_tau[[m]] <- rep(0,D[m])
}
# ARD prior: alpha
if (opts$init.alpha == "datavar") {
alpha <- matrix(NA,M,K)
for(m in 1:M)
alpha[m,] <- sum(datavar[[m]] - 1/tau[[m]])
} else {
alpha <- matrix(opts$init.alpha,M,K)          # The mean of the ARD precisions
}
logalpha <- matrix(1,M,K)       # The mean of the log ARD precisions
b_alpha <- matrix(1,M,K)        # b parameter of the q(alpha) gamma distribution
a_alpha <- a0_alpha + D/2       # a parameter of the q(alpha) gamma distribution
# The projections are the first update, no need for random initialisation
# MAYBE MODIFY THAT SO THAT THE WEIGHTS CAN ALSO BE INITIALISED
W <- vector("list",length=M)    # The means
covW <- vector("list",length=M) # The covariances
WW <- vector("list",length=M)   # The second moments
for(m in 1:M) {
W[[m]] <- matrix(0,D[m],K)
covW[[m]] <- lapply(1:D[m], function(x) diag(1,K)) #vector("list",length=D[m])
WW[[m]] <- lapply(1:D[m], function(x) diag(1,K)) #vector("list",length=D[m])
}
# Some constants for speeding up the computation
Yconst <- lapply(Y, function(x) { apply(x**2,2,sum) } )
lblik.const <- -N*Ds/2*log(2*pi)
digammaa_tau <- digamma(a_tau)
lb.qt.const <- -Ds*lgamma(a_tau)
lb.qt.const
a_tau
tua
digamma(a_tau)
Ds*lgamma(a0_tau)
a0_tau
lgamma(a0_tau)
Ds
Ds*lgamma(a0_tau)
a0_tau = 1e-5
Ds*lgamma(a0_tau)
lgamma(a0_tau)
lgamma(a0_tau)*9484
source("http://bioconductor.org/biocLite.R")
biocLite("rgl")
library(dplyr)
library(tidyr)
library(DESeq2)
library(ggplot2)
data(e, package="pace") # DESeqDataSet object
e <- updateObject(e)
# Define options
opts <- list()
opts$transformation <- "vst"  # 'log' or 'vst'
######################
## Load annotations ##
######################
mRNA_file <- "/Users/ricard/data/ensembl/human/v75/BioMart/protein_coding/Hsapiens_genes_BioMart.75.txt"
lincRNA_file <- "/Users/ricard/data/ensembl/human/v75/BioMart/ncRNA/Hsapiens_lincRNA_BioMart.75.txt"
miRNA_file <- "/Users/ricard/data/ensembl/human/v75/BioMart/ncRNA/Hsapiens_miRNA_BioMart.75.txt"
mRNA = read.csv(file=mRNA_file,header=T,sep="\t",stringsAsFactors=F)
miRNA = read.csv(file=miRNA_file,header=T,sep="\t",stringsAsFactors=F)
lincRNA = read.csv(file=lincRNA_file,header=T,sep="\t",stringsAsFactors=F)
mRNA$biotype <- "mRNA"
miRNA$biotype <- "miRNA"
lincRNA$biotype <- "lincRNA"
metadata <- do.call("rbind", list(mRNA,miRNA,lincRNA))
sum(duplicated(metadata$ens_id))
asd = metadata[duplicated(metadata$ens_id),]
View(asd)
e
e <- subset(e,rownames(e) %in% metadata$ens_id)
e
# (Q) I am doing all these filtering steps to remove gene outliers
e <- subset(e,rownames(e) %in% miRNA$ens_id)
e
assays(e)
f <- counts(e)
dim(f)
View(f)
hist(f)
rowSums(f) > 50
sum(rowSums(f) > 50)
View(f)
rowSums(f>0) > 0.5*ncol(f)
sum(rowSums(f>0) > 0.5*ncol(f))
sum( (rowSums(f)>50) & (rowSums(f>0) > 0.5*ncol(f)) )
sum( (rowSums(f)>50) || (rowSums(f>0) > 0.5*ncol(f)) )
rowSums(f)>50)
(rowSums(f)>50)
(rowSums(f>0) > 0.5*ncol(f))
sum( (rowSums(f)>50) && (rowSums(f>0) > 0.5*ncol(f)) )
sum( (rowSums(f)>50) & (rowSums(f>0) > 0.5*ncol(f)) )
e <- subset(e,rownames(e) %in% lincRNA$ens_id)
f <- counts(e)
sum( (rowSums(f)>50) & (rowSums(f>0) > 0.5*ncol(f)) )
f
lincRNA$ens_id
rownames(e)
data(e, package="pace") # DESeqDataSet object
e <- updateObject(e)
asd <- subset(e,rownames(e) %in% lincRNA$ens_id)
f <- counts(asd)
sum( (rowSums(f)>50) & (rowSums(f>0) > 0.5*ncol(f)) )
rowSums(f)
View(f)
sum( (rowSums(f)>100) & (rowSums(f>0) > 0.5*ncol(f)) )
"""
Script to process the expression data
(1) Filtering: specific biotypes, lowly expressed genes, outliers
(2) Normalisation
(3) Transformation: vst or log
Here we include not only protein-coding mRNAs but also lincRNAs and miRNAs
(Q) Should the normalisation and filtering steps be performed in the concatenated matrix or at each separately?
"""
library(dplyr)
library(tidyr)
library(DESeq2)
library(ggplot2)
data(e, package="pace") # DESeqDataSet object
e <- updateObject(e)
# saveRDS(e,"/Users/ricard/git/britta/processed_data/expr/expr_deseq_unfilt.rds")
# e <- readRDS("/Users/ricard/git/britta/processed_data/expr/expr_deseq_unfilt.rds")
# Define options
opts <- list()
opts$transformation <- "vst"  # 'log' or 'vst'
######################
## Load annotations ##
######################
mRNA_file <- "/Users/ricard/data/ensembl/human/v75/BioMart/protein_coding/Hsapiens_genes_BioMart.75.txt"
lincRNA_file <- "/Users/ricard/data/ensembl/human/v75/BioMart/ncRNA/Hsapiens_lincRNA_BioMart.75.txt"
miRNA_file <- "/Users/ricard/data/ensembl/human/v75/BioMart/ncRNA/Hsapiens_miRNA_BioMart.75.txt"
mRNA = read.csv(file=mRNA_file,header=T,sep="\t",stringsAsFactors=F)
miRNA = read.csv(file=miRNA_file,header=T,sep="\t",stringsAsFactors=F)
lincRNA = read.csv(file=lincRNA_file,header=T,sep="\t",stringsAsFactors=F)
mRNA$biotype <- "mRNA"
miRNA$biotype <- "miRNA"
lincRNA$biotype <- "lincRNA"
metadata <- do.call("rbind", list(mRNA,miRNA,lincRNA))
# TO-DO: THIS SANITY CHECK
# sum(duplicated(metadata$ens_id))
# asd = metadata[duplicated(metadata$ens_id),]
#################
## Filter data ##
#################
## Keep only protein-coding high-quality genes ##
e <- subset(e,rownames(e) %in% metadata$ens_id)
## Remove genes that are lowly expressed ##
# (Q) I am doing all these filtering steps to remove gene outliers
# This doesnt work well if there is an outlier with huge expression
e <- e[ rowSums(counts(e)) > 75, ]
# this doesnt work well if the gene is not expressed at all in one of the conditions
e <- e[ rowSums(counts(e)>0) > 0.5*ncol(e), ]
View(counts(e))
count_matrix <- counts(e)
# calculate size factors
e <- estimateSizeFactors(e)
## Option 1: log transformation ##
if (opts$transformation == "log")
e <- rlogTransformation(e)
## Option 2: VST transformation ##
# calculate dispersions
if (opts$transformation == "vst") {
e <- estimateDispersions(e) # DESeqTransform object
# plotDispEsts(e, main="DESeq: Per-gene dispersion estimates")
e <- varianceStabilizingTransformation(e)
}
## Assess the transformation ##
# Mean vs variance plot
foo <- data.frame(sd=apply(assay(e),1,sd), mean=apply(assay(e),1,mean) )
ggplot(foo, aes(x=mean, y=sd)) +
geom_point() +
stat_smooth() +
xlab('Mean') + ylab('Standard deviation')
# Extract expression matrix
expr_matrix = t(assay(e))
rownames(e)
filter(e, rownames %in% mRNA$ens_id)
mRNA_e <- subset(e,rownames(e) %in% mRNA$ens_id)
mRNA_e <- subset(e,rownames(e) %in% mRNA$ens_id)
miRNA_e <- subset(e,rownames(e) %in% miRNA$ens_id)
lincRNA_e <- subset(e,rownames(e) %in% lincRNA$ens_id)
mRNA_e <- subset(e,rownames(e) %in% mRNA$ens_id) %>% assay %>% t
dim(mRNA_e)
edf_list <- lapply(ematrix_list, function(e) e %>% as.data.frame %>% add_rownames("sample") %>% gather(gene,expr,-sample))
ematrix_list <- list(mRNA_e,miRNA_e,lincRNA_e)
edf_list <- lapply(ematrix_list, function(e) e %>% as.data.frame %>% add_rownames("sample") %>% gather(gene,expr,-sample))
head(ematrix_list[[1]])
dim(ematrix_list[[1]])
ematrix_list[[1]] %>% as.data.frame %>% add_rownames("sample") %>% gather(gene,expr,-sample)
edf_list <- lapply(ematrix_list, function(e) e %>% as.data.frame %>% add_rownames("sample") %>% gather(gene,expr,-sample))
length(ematrix_list)
mRNA_e <- subset(e,rownames(e) %in% mRNA$ens_id) %>% assay %>% t
miRNA_e <- subset(e,rownames(e) %in% miRNA$ens_id) %>% assay %>% t
lincRNA_e <- subset(e,rownames(e) %in% lincRNA$ens_id) %>% assay %>% t
ematrix_list[[2]] %>% as.data.frame %>% add_rownames("sample") %>% gather(gene,expr,-sample)
ematrix_list[[2]]
subset(e,rownames(e) %in% miRNA$ens_id) %>% assay %>% t
miRNA_e <- subset(e,rownames(e) %in% miRNA$ens_id) %>% assay %>% t
lincRNA_e <- subset(e,rownames(e) %in% lincRNA$ens_id) %>% assay %>% t
ematrix_list <- list(mRNA_e,miRNA_e,lincRNA_e)
ematrix_list[[2]]
ematrix_list[[3]]
edf_list <- lapply(ematrix_list, function(e) e %>% as.data.frame %>% add_rownames("sample") %>% gather(gene,expr,-sample))
rownmaes(edf_list) <- c("mRNA","miRNA","lincRNA")
rownames(edf_list) <- c("mRNA","miRNA","lincRNA")
length(edf_list)
names(edf_list) <- c("mRNA","miRNA","lincRNA")
mRNA_types <- c("mRNA","miRNA","lincRNA")
m=1
saveRDS(edf_list[[m]], sprintf("/Users/ricard/git/britta/processed_data/expr/expr_df_%s.rds", mRNA_types[m]) )
saveRDS(ematrix_list[[m]], sprintf("/Users/ricard/git/britta/processed_data/expr/expr_matrix_%d.rds", mRNA_types[m]) )
saveRDS(ematrix_list[[m]], sprintf("/Users/ricard/git/britta/processed_data/expr/expr_matrix_%s.rds", mRNA_types[m]) )
# Save
for (m in length(mRNA_types)) {
saveRDS(edf_list[[m]], sprintf("/Users/ricard/git/britta/processed_data/expr/expr_df_%s.rds", mRNA_types[m]) )
saveRDS(ematrix_list[[m]], sprintf("/Users/ricard/git/britta/processed_data/expr/expr_matrix_%s.rds", mRNA_types[m]) )
}
setwd("/Users/ricard/git/scGFA/R/R")
source("loadModel.R")
file = "/Users/ricard/git/britta/scGFA/fullmodel300.hdf5"
model <- loadModel(file)
meta <- read.table("/Users/ricard/git/britta/processed_data/joined/metadata.txt", sep="\t", header=T)
source("training_statistics.R")
elbo_trainCurve(model)
names(Y)
Y <- model@Data
names(Y)
View(Y$surv1)
View(Y$surv5)
model@TrainStats
scatterPlot(model, idx=10, idy=4, colour_by=bool, shape_by=bool )
source("scatterplot.R")
bool <- c(FALSE,TRUE)[meta$ighv]
scatterPlot(model, idx=10, idy=4, colour_by=bool, shape_by=bool )
mean(Y$expr[meta$ighv=="U","ENSG00000075651"], na.rm=T)
asd <- readRDS("/Users/ricard/git/britta/processed_data/expr/filt2/expr_matrix.rds")
genes <- colnames(asd)
w <- e$SW$expr$ESW[,10]
names(w) <- genes
colnames(Y$expr) <- genes
mean(Y$expr[meta$ighv=="U","ENSG00000075651"], na.rm=T)
mean(Y$expr[meta$ighv=="M","ENSG00000075651"], na.rm=T)
library(pace)
pace
data(surv)
View(survT)
View(meta)
data(patmeta)
View(patmeta)
